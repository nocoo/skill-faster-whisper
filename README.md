# üé§ Claude Code Skill - Faster Whisper

> Fast speech-to-text transcription powered by faster-whisper with CTranslate2. Supports 99 languages, multiple output formats, GPU acceleration, and VAD filtering. Zero configuration required.

[![Skill](https://img.shields.io/badge/Claude_Code-Skill-blue)](https://claude.com/claude-code)
[![Python](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

---

**[ÁÆÄ‰Ωì‰∏≠Êñá](./README.zh-CN.md) | English**

---

## üìã Prerequisites

- **Python 3.9+**
- **Virtual environment** (recommended)

## üöÄ Installation

### Step 1: Clone or Download

```bash
git clone https://github.com/nocoo/skill-fast-whisper.git
cd skill-fast-whisper
```

### Step 2: Install Dependencies

```bash
# Create virtual environment
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install faster-whisper
pip install faster-whisper
```

### Step 3: Configure (Optional)

```bash
cp scripts/config.example.json scripts/config.json
# Edit scripts/config.json to set your preferred defaults
```

## ‚ö° Quick Start

```bash
# Basic transcription (auto-detect language)
python scripts/transcribe.py audio.mp3

# With output file
python scripts/transcribe.py audio.mp3 --output transcript.txt

# Generate subtitles
python scripts/transcribe.py video.mp4 --format srt --output video.srt
```

## ‚ú® Features

| Feature | Description |
|---------|-------------|
| **üöÄ Fast** | Up to 4x faster than openai/whisper |
| **üíæ Efficient** | INT8 quantization for low memory usage |
| **üåè Multi-language** | 99 languages with auto-detection |
| **üìù Timestamps** | Segment and word-level timestamps |
| **üéØ VAD Filter** | Remove silence automatically |
| **üìÑ Formats** | Text, SRT, JSON output |
| **üéÆ GPU Support** | NVIDIA CUDA acceleration |

## üìä Model Comparison

| Model | Size | Speed | Accuracy |
|-------|------|-------|----------|
| tiny | 39MB | ‚ö°‚ö°‚ö° | Basic |
| base | 74MB | ‚ö°‚ö° | Good |
| small | 244MB | ‚ö° | Very Good |
| medium | 769MB | ‚ö° | Excellent |
| **large-v3** | 1550MB | Best | ‚òÖ Best |

## üìñ Usage Examples

```bash
# Basic transcription (auto-detect language)
python scripts/transcribe.py audio.mp3

# Specify language
python scripts/transcribe.py audio.mp3 --language zh

# Save to file
python scripts/transcribe.py audio.mp3 --output transcript.txt

# Generate subtitles
python scripts/transcribe.py video.mp4 --format srt --output video.srt

# Use smaller model (faster)
python scripts/transcribe.py audio.mp3 --model small

# GPU acceleration (NVIDIA)
python scripts/transcribe.py audio.mp3 --device cuda --compute-type float16
```

## ‚öôÔ∏è Configuration

Copy the example config:

```bash
cp scripts/config.example.json scripts/config.json
```

Edit `scripts/config.json` to set defaults:

```json
{
  "model_size": "large-v3",
  "device": "cpu",
  "compute_type": "int8",
  "language": null,
  "beam_size": 5,
  "vad_filter": true,
  "word_timestamps": false
}
```

## üéõÔ∏è Command-Line Options

```
positional arguments:
  audio_file            Path to audio file

options:
  -h, --help            Show help
  --model MODEL         Model size (default: large-v3)
  --device DEVICE       cpu or cuda (default: cpu)
  --compute-type TYPE   float16, int8, int8_float16 (default: int8)
  --language LANG       Language code or auto (default: auto)
  --task TASK           transcribe or translate (default: transcribe)
  --beam-size N         Beam size (default: 5)
  --vad-filter          Enable VAD filter
  --word-timestamps     Include word timestamps
  --output PATH         Save to file
  --format FMT          text, srt, json, json_full (default: text)
  --verbose             Show detailed progress
```

## üìÅ Project Structure

```
skill-fast-whisper/
‚îú‚îÄ‚îÄ .gitignore              # Git ignore rules
‚îú‚îÄ‚îÄ LICENSE                 # MIT License
‚îú‚îÄ‚îÄ README.md               # This file (English)
‚îú‚îÄ‚îÄ README.zh-CN.md         # Chinese version
‚îú‚îÄ‚îÄ SKILL.md                # Skill definition (used by Claude)
‚îú‚îÄ‚îÄ requirements.txt        # Python dependencies
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ config.example.json # Configuration template
‚îÇ   ‚îú‚îÄ‚îÄ config.json         # Your configuration (not in git)
‚îÇ   ‚îî‚îÄ‚îÄ transcribe.py       # Core transcription script
‚îî‚îÄ‚îÄ venv/                   # Virtual environment (not in git)
```

## üìÑ Output Formats

### Text (default)
```
[0.00s -> 2.50s] Hello world
[2.50s -> 5.00s] This is a test
```

### SRT (subtitles)
```
1
00:00:00,000 --> 00:00:02,500
Hello world

2
00:00:02,500 --> 00:00:05,000
This is a test
```

### JSON
```json
{
  "language": "en",
  "language_probability": 0.95,
  "duration": 5.0,
  "segments": [...]
}
```

## ‚ö° Performance Tips

### For CPU (most users)
- Use `int8` compute type (default)
- Try `small` model for faster results
- Reduce `beam_size` to 1 for speed

### For GPU (NVIDIA)
- Use `--device cuda`
- Use `float16` compute type
- Models process 3-5x faster

## ‚ùì Troubleshooting

### "faster-whisper not installed"
```bash
pip install faster-whisper
```

### "Out of memory"
- Use smaller model: `--model small`
- Use int8: `--compute-type int8`

### Slow transcription
- Use smaller model
- Reduce beam size: `--beam-size 1`
- Consider GPU if available

### Poor accuracy
- Specify correct language: `--language zh`
- Use larger model: `--model large-v3`
- Check audio quality (16kHz+ recommended)

## üîß Technical Details

- **Model**: Based on OpenAI Whisper
- **Engine**: CTranslate2 for efficient inference
- **Audio**: PyAV decodes MP3/WAV/MP4/etc. (no FFmpeg needed)
- **Languages**: 99 languages supported

## üî¢ Configuration Reference

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `model_size` | string | `"large-v3"` | Model size: tiny/base/small/medium/large-v3 |
| `device` | string | `"cpu"` | Device: cpu or cuda |
| `compute_type` | string | `"int8"` | Computation: float16/int8/int8_float16 |
| `language` | string/null | `null` | Language code (null = auto-detect) |
| `beam_size` | int | `5` | Beam search size (1 = greedy) |
| `vad_filter` | boolean | `true` | Enable voice activity detection |
| `word_timestamps` | boolean | `false` | Include word-level timestamps |

## üìÑ License

MIT License - see [LICENSE](LICENSE) for details.

## üôè Acknowledgments

- [faster-whisper](https://github.com/SYSTRAN/faster-whisper) by SYSTRAN
- [OpenAI Whisper](https://github.com/openai/whisper)
- [CTranslate2](https://github.com/OpenNMT/CTranslate2)
- [Claude Code](https://claude.com/claude-code) - AI programming assistant

## ü§ù Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## üë®‚Äçüíª Author

Created by [@nocoo](https://github.com/nocoo)

## üìû Support

For issues with:
- **This skill**: Check [SKILL.md](SKILL.md)
- **faster-whisper**: Visit [GitHub](https://github.com/SYSTRAN/faster-whisper)
- **Claude Code**: Visit [GitHub](https://github.com/anthropics/claude-code)

---

**[ÁÆÄ‰Ωì‰∏≠Êñá](./README.zh-CN.md) | English**
